from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import pandas as pd
from tabulate import tabulate

def regression_summary(X, y):
    """
    Function to produce a regression summary table with standard errors for coefficients.

    Parameters:
    X (numpy array or pandas DataFrame): Features
    y (numpy array or pandas Series): Target values
    """
    # Split the data into training/testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Create linear regression object
    reg = LinearRegression()

    # Train the model using the training sets
    reg.fit(X_train, y_train)

    # Make predictions using the testing set
    y_pred = reg.predict(X_test)

    # Calculate residuals
    residuals = y_test - y_pred
    residual_sum_of_squares = np.sum(residuals ** 2)

    # Degrees of freedom
    degrees_of_freedom = X_train.shape[0] - X_train.shape[1] - 1

    # Variance of residuals
    residual_variance = residual_sum_of_squares / degrees_of_freedom

    # Covariance matrix of the coefficients
    X_train_with_intercept = np.column_stack((np.ones(X_train.shape[0]), X_train))
    cov_matrix = np.linalg.inv(X_train_with_intercept.T.dot(X_train_with_intercept)) * residual_variance

    # Standard errors of the coefficients (square root of diagonal of covariance matrix)
    std_errors = np.sqrt(np.diag(cov_matrix)[1:])

    # Prepare the data for the table
    coefficients = reg.coef_
    intercept = reg.intercept_
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # Create a pandas DataFrame to store the results
    summary_data = {
        "Metric": ["Intercept", "Mean Squared Error", "R-squared"] + [f"Coefficient {i+1}" for i in range(len(coefficients))],
        "Value": [intercept, mse, r2] + list(coefficients),
        "Std Error": ["-"] + ["-"] + ["-"] + list(std_errors)
    }

    summary_df = pd.DataFrame(summary_data)

    # Use tabulate to print the table
    print(tabulate(summary_df, headers='keys', tablefmt='grid', showindex=False))

# Example usage with dummy data
# X = np.random.rand(100, 2)  # 100 samples, 2 features
# y = X[:, 0] * 3 + X[:, 1] * 2 + np.random.randn(100) * 0.1  # linear relationship with noise
# regression_summary(X, y)